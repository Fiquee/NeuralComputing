{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhccwHuvOzJ5"
      },
      "source": [
        "# Text Classification Example with Simple Recurrent Neural Network (RNN)\n",
        "\n",
        "Source: https://coderzcolumn.com/tutorials/artificial-intelligence/pytorch-rnn-for-text-classification-tasks\n",
        "\n",
        "Some examples uses PyTorch Field, which is deprecated. So you need to look for the latest examples when Googling about. Remember that for text classification or NLP tasks, the text not only refers to the characters/words/sentences in the language but includes others such as punctuation mark, commas, exclamation mark etc. For text classification/nlp tasks, you'll need to install dependecies such as torchtext, spacy etc. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HtDBaqBtQlm",
        "outputId": "05d5b371-1714-4b71-e30f-52fa4baad327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "  Downloading torchtext-0.12.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
            "Requirement already satisfied: torch==1.11.0 in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchtext) (1.11.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchtext) (1.21.2)\n",
            "Requirement already satisfied: requests in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchtext) (2.26.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchtext) (4.62.2)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==1.11.0->torchtext) (3.10.0.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext) (1.26.6)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext) (2.0.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext) (2021.10.8)\n",
            "Requirement already satisfied: colorama in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->torchtext) (0.4.4)\n",
            "Installing collected packages: torchtext\n",
            "Successfully installed torchtext-0.12.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: You are using pip version 21.1.3; however, version 22.1.2 is available.\n",
            "You should consider upgrading via the 'c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchdata\n",
            "  Downloading torchdata-0.3.0-py3-none-any.whl (47 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchdata) (2.26.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchdata) (1.26.6)\n",
            "Requirement already satisfied: torch==1.11.0 in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchdata) (1.11.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==1.11.0->torchdata) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchdata) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchdata) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchdata) (2.0.7)\n",
            "Installing collected packages: torchdata\n",
            "Successfully installed torchdata-0.3.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: You are using pip version 21.1.3; however, version 22.1.2 is available.\n",
            "You should consider upgrading via the 'c:\\users\\afiq irfan\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "# !pip install torchtext\n",
        "# !pip install torchdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaOtrIUqm50K"
      },
      "source": [
        "# Building vocabulary\n",
        "\n",
        "A slightly tricky part for text classification/nlp task is the tokenization-vectorization process where we are converting the words in the text into numbers/vectors. Be aware that tokenization can also be done on character level (eg. character classification/prediction task).\n",
        "\n",
        "In this example functions such as `get_tokenizer` and `build_vocab_from_iterator` are utilised. When dealing with text datasets it is commons for python generators to be used. \n",
        "\n",
        "Please take note that in this example only `<UNK>` is used and there is no `<pad>` . Most probably because the vocabulary takes all the unique words from the dataset. In cases where the vocabulary is high, it is common to take the most frequent words and ignore low frequency words (such as Pneumonoultramicroscopicsilicovolcanoconiosis ) ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGg0egM2sLRn",
        "outputId": "0b76efd3-6582-4ed3-965c-5835144e8de4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Afiq Irfan\\AppData\\Local\\Temp\\ipykernel_12628\\2096430348.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
            "  from collections import Iterable\n",
            "c:\\Users\\Afiq Irfan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\datapipes\\utils\\common.py:24: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "98635"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext import data \n",
        "from torch.utils.data import DataLoader\n",
        "from collections import Iterable\n",
        "\n",
        "\n",
        "train, test = torchtext.datasets.AG_NEWS()\n",
        "\n",
        "labels = [\"world\",\"sports\",\"biz\",\"science\"]\n",
        "\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "tokenizer  =  get_tokenizer(\"basic_english\")\n",
        "\n",
        "def build_vocab(datasets):\n",
        "    for dataset in datasets:\n",
        "        for _, text in dataset:\n",
        "            yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(build_vocab([train, test]), specials=[\"<UNK>\"])\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "len(vocab.get_itos())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEfPKbCSoikj"
      },
      "source": [
        "Here the index of the vocabulary is shown. Each unique word has its own index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT_fLRo_scTK",
        "outputId": "269ac2a8-041e-498e-c93f-1962e3cb11a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indexes for the sentence 'what is your name?'\n",
            "[183, 21, 379, 971]\n",
            "\n",
            " Tokens and indexes for the sentence 'Hello how are you?, Welcome to CoderzColumn!!'\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(['hello',\n",
              "  'how',\n",
              "  'are',\n",
              "  'you',\n",
              "  '?',\n",
              "  ',',\n",
              "  'welcome',\n",
              "  'to',\n",
              "  'coderzcolumn',\n",
              "  '!',\n",
              "  '!'],\n",
              " [12388, 355, 42, 164, 80, 3, 3298, 4, 0, 747, 747])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = tokenizer(\"Hello how are you?, Welcome to CoderzColumn!!\")\n",
        "indexes = vocab(tokens)\n",
        "\n",
        "print(\"Indexes for the sentence 'what is your name?'\")\n",
        "print(vocab([\"what\",\"is\",\"your\",\"name\"]))\n",
        "\n",
        "print(\"\\n Tokens and indexes for the sentence 'Hello how are you?, Welcome to CoderzColumn!!'\")\n",
        "tokens, indexes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V5p98Ex-sfM8"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "train_dataset, test_dataset  = torchtext.datasets.AG_NEWS()\n",
        "train_dataset, test_dataset  = to_map_style_dataset(train_dataset), to_map_style_dataset(test_dataset)\n",
        "\n",
        "target_classes = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
        "\n",
        "max_words = 25\n",
        "\n",
        "def vectorize_batch(batch):\n",
        "    Y, X = list(zip(*batch))\n",
        "    X = [vocab(tokenizer(text)) for text in X]\n",
        "    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] ## Bringing all samples to max_words length.\n",
        "\n",
        "    return torch.tensor(X, dtype=torch.int32), torch.tensor(Y) - 1 ## We have deducted 1 from target names to get them in range [0,1,2,3] from [1,2,3,4]\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1024, collate_fn=vectorize_batch, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset , batch_size=1024, collate_fn=vectorize_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg7ygs9Novqm"
      },
      "source": [
        "# Defining the RNN\n",
        "\n",
        "In this example one embedding layer followed by RNN and then followed by a linear layer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yYzjnnmKsiKE"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "embed_len = 50\n",
        "hidden_dim = 50\n",
        "n_layers=1\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embed_len)\n",
        "        self.rnn = nn.RNN(input_size=embed_len, hidden_size=hidden_dim, num_layers=n_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, len(target_classes))\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        output, hidden = self.rnn(embeddings, torch.randn(n_layers, len(X_batch), hidden_dim))\n",
        "        return self.linear(output[:,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vw3X2i0sm68",
        "outputId": "65b70d03-936e-4e13-fe60-c9e4d2701094"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RNNClassifier(\n",
              "  (embedding_layer): Embedding(98635, 50)\n",
              "  (rnn): RNN(50, 50, batch_first=True)\n",
              "  (linear): Linear(in_features=50, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn_classifier = RNNClassifier()\n",
        "\n",
        "rnn_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11ZD26AsspBj",
        "outputId": "a99bbe71-463f-4fd3-c035-4689e4b1f28e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer : Embedding(98635, 50)\n",
            "Parameters : \n",
            "torch.Size([98635, 50])\n",
            "\n",
            "Layer : RNN(50, 50, batch_first=True)\n",
            "Parameters : \n",
            "torch.Size([50, 50])\n",
            "torch.Size([50, 50])\n",
            "torch.Size([50])\n",
            "torch.Size([50])\n",
            "\n",
            "Layer : Linear(in_features=50, out_features=4, bias=True)\n",
            "Parameters : \n",
            "torch.Size([4, 50])\n",
            "torch.Size([4])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for layer in rnn_classifier.children():\n",
        "    print(\"Layer : {}\".format(layer))\n",
        "    print(\"Parameters : \")\n",
        "    for param in layer.parameters():\n",
        "        print(param.shape)\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMApCTjpBYBwmzyBT8MBfpF",
      "name": "10. Text Classification  With Simple RNNs _2021_22.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "3ced2f4eaaec4a5ad21e54a5682a43cb37ebcff431dffc69052d7e4efcca1b3f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
